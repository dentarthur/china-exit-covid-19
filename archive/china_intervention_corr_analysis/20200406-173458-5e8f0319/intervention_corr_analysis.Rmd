---
title: "China Intervention Correlation Analysis"
author: "Kylie Ainslie"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  word_document:
    fig_width: 7
    fig_height: 5
    fig_caption: true
    highlight: "tango"
    reference_docx: word_style.docx
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,
                      results = "hide")
```
# Read in data
1. New daily confirmed cases from China CDC
2. Exante daily intracity movement data
3. Back calculated new infections
```{r read_in_data}
# case data
new_case_dat <- readr::read_csv("china_new_case_data_imported.csv") 
# wrangle into incidence data
incidence_dat <- new_case_dat %>% 
                    group_by(province) %>%
                    select(province, date_confirm, new_cases_wo_imported) %>%
                    mutate(date_confirm = as.Date(date_confirm),
                           new_cases_wo_imported = ifelse(is.na(new_cases_wo_imported) | new_cases_wo_imported < 0, 
                                                          0, new_cases_wo_imported)) %>%
                    rename("dates" = "date_confirm", "I" = "new_cases_wo_imported") 
# movement data
# movement_dat <- readr::read_csv("exante_movement_data.csv")[,-1]
movement_top6 <- readRDS("movement_province_level_subset.rds")
```

```{r prop_cases_hubei}
case_sums <- new_case_dat %>% 
              filter(date_confirm < '2020-02-15') %>% 
              group_by(province) %>% 
              summarise_at(.vars = "new_cases", .funs = sum)
prop_hubei <- case_sums[case_sums$province == "hubei",2] / sum(case_sums$new_cases)
```

# Estimate R_t for confirmed case data
```{r estimate_R, echo = T, results = 'hide'}
#####################################################
### COVID19 spread with Chinese movement patterns ###
#####################################################
# 1. Estimating R_t over time for each province in China using EpiEstim
# 2. Determining most highly correlated lag time
# 3. Determine rolling correlation using runCor (at weekly and biweekly resolution)

### 1. Estimating R_t with EpiEstim
si_mean = 6.48
si_std = 3.83
# serial interval estimate used: mean = 6.48, sd =  3.83
# from Neil's IBM model

r <- incidence_dat %>%
       tidyr::nest(gg = -"province") %>%
       mutate_at("gg", purrr::map,function(x) estimate_R(x, method="parametric_si",
                                                            config = make_config(list(mean_si = si_mean, 
                                                                                      std_si = si_std)))
                 )
# loop through provinces to concatenate 
R_t <- list()
for(i in 1:length(r$province)){
   R_t[[i]] <- r$gg[[i]]$R %>% 
                 mutate(province = r$province[i],
                        date_start = r$gg[[i]]$dates[t_start],
                        date_end = r$gg[[i]]$dates[t_start][t_end]) %>%
                        rename(r_mean = `Mean(R)`, r_q2.5 = `Quantile.0.025(R)`,
                               r_q97.5 = `Quantile.0.975(R)`,
                               r_median = `Median(R)`) %>%
                        select(date_start, date_end, province, r_mean, r_q2.5,
                               r_q97.5, r_median)
}

r_dat <- bind_rows(R_t)

```

# Combine R_t estimates and pop-weighted avg movement data for top 6 provinces
```{r join_r_est_and_movement}
movement_top6 <- movement_top6 %>% 
                    filter(year == 2020, province != "anhui") %>%
                    mutate(year = as.numeric(year)) 
r_top6 <- r_dat %>% filter(province %in% c("hubei", "guangdong", "henan", "zhejiang",
                                         "hunan", "beijing", "hong_kong_sar"))
dat_all_top6 <- left_join(r_top6, movement_top6, by=c("date_end" = "date", "province")) %>%
                    select(-date_start, -year, -month_day, -id)

```

# Determine cross correlation between R_t and movement
```{r cross_corr}
### cross correlation
# restrict cross correlation to peak of epidemic
dat_top6_peak <- dat_all_top6 %>% filter(date_end < '2020-02-15')

hubei <- dat_top6_peak %>% filter(province == "hubei", !is.na(movement))
hubei_corr <- ccf(hubei$movement, hubei$r_mean, lag = 10)
lag_hubei <- hubei_corr$lag[which(hubei_corr$acf == max(hubei_corr$acf))] 

# plot hubei corr
plot(hubei_corr, main = "", cex.lab = 1.25, cex.axis = 1.25)
axis(1, at=c(seq(-10:10)-11),cex.axis=1.25)

```

```{r cross_corr_lag_dist}
### cross correlation sensitivity analysis
  # look at distribution of lag time with highest corr for all locations
movement_2020 <- movement_top6 %>% 
                    filter(year == 2020) %>%
                    mutate(year = as.numeric(year)) 

rhos <- dat_top6_peak %>%
          filter(!is.na(movement)) %>%
          tidyr::nest(gg = -"province") %>%
          mutate_at("gg",purrr::map,
                    function(x) ccf(x$movement, x$r_mean, lag.max = 10))
max_lag <- numeric(nrow(rhos))
for (p in 1:nrow(rhos)){
  df <- tibble(province = rhos$province[p],lags = rhos$gg[[p]]$lag[,1,1],cc = rhos$gg[[p]]$acf[,1,1]) %>%
          filter(lags < 1)
  max_lag[p] <- df$lags[which(df$cc == max(df$cc))]
}
lag_df <- tibble(province = rhos$province, lag = max_lag)
p_lags <- ggplot(lag_df, aes(x=lag)) + 
              geom_histogram(binwidth = 2) +
              theme(legend.position = "none",
                      panel.grid.major = element_blank(),
                      panel.grid.minor = element_blank(),
                      panel.background = element_blank()
                    )
ggsave("figure_S2.png", p_lags,
  width = 4, height = 4,
  dpi = 500)
```

```{r lag_variable}
# create date_lag variable using hubei only
dat_all_top6a <- dat_all_top6 %>% mutate(date_lag = date_end + lag_hubei) %>%
                  select(-date_end, -movement)
dat_all_top6b <- left_join(dat_all_top6a, movement_top6, 
                           by = c("date_lag" = "date", "province"))  %>%
                  select(-id, -month_day, -year)

# create lag variable using lag for each region
dat_all_top6c <- left_join(dat_all_top6, lag_df, by = "province") %>% 
                  group_by(province) %>%
                  mutate(date_lag = date_end + lag) %>%
                  select(-date_end, -movement) %>%
                  filter(!is.na(date_lag))
dat_all_top6d <- left_join(dat_all_top6c, movement_top6, 
                           by = c("date_lag" = "date", "province"))  %>%
                  select(-id, -month_day, -year)
```

# Determine biweekly rolling correlation between R_t and movement
```{r rolling_corr}
### determine rolling biweekly correlation
# rolling correlation - biweekly
rolling_corr_bi <- dat_all_top6b %>%
                      group_by(province) %>%
                      filter(!is.na(movement)) %>%
                      tq_transmute_xy(x          = movement, 
                                      y          = r_mean,
                                      mutate_fun = runCor,
                                      n          = 14,
                                      col_rename = "rolling.corr.biweekly")

# rolling correlation - Hubei vs R_t in other provinces
dat_all_top6b <- dat_all_top6b %>%
                  group_by(province) %>%
                  mutate(movement_hubei = dat_all_top6b[dat_all_top6b$province == 'hubei',]$movement)

rolling_corr_hubei <- dat_all_top6b %>%
                        group_by(province) %>%
                        filter(!is.na(movement_hubei)) %>%
                        tq_transmute_xy(x          = movement_hubei, 
                                        y          = r_mean,
                                        mutate_fun = runCor,
                                        n          = 14,
                                        col_rename = "rolling.corr.hubei")

rolling_corr <- left_join(rolling_corr_bi, rolling_corr_hubei, 
                          by = c("province", "date_lag")) %>%
                  mutate(date_lag = as.Date(date_lag))

dat_corr <- left_join(dat_all_top6b, rolling_corr, by = c("province", "date_lag"))
```

```{r rolling_corr_sensitivity}
### determine rolling biweekly correlation
# rolling correlation - biweekly
rolling_corr_bi2 <- dat_all_top6d %>%
                      group_by(province) %>%
                      filter(!is.na(movement)) %>%
                      tq_transmute_xy(x          = movement, 
                                      y          = r_mean,
                                      mutate_fun = runCor,
                                      n          = 14,
                                      col_rename = "rolling.corr.biweekly") %>%
                      mutate(date_lag = as.Date(date_lag))

# rolling correlation - Hubei vs R_t in other provinces
# dat_all_top6b <- dat_all_top6d %>%
#                   group_by(province) %>%
#                   mutate(movement_hubei = dat_all_top6d[dat_all_top6b$province == 'hubei',]$movement)
# 
# rolling_corr_hubei <- dat_all_top6b %>%
#                         group_by(province) %>%
#                         filter(!is.na(movement_hubei)) %>%
#                         tq_transmute_xy(x          = movement_hubei, 
#                                         y          = r_mean,
#                                         mutate_fun = runCor,
#                                         n          = 14,
#                                         col_rename = "rolling.corr.hubei")

# rolling_corr <- left_join(rolling_corr_bi, rolling_corr_hubei, 
#                           by = c("province", "date_lag")) %>%
#                   mutate(date_lag = as.Date(date_lag))

dat_corr2 <- left_join(dat_all_top6d, rolling_corr_bi2, by = c("province", "date_lag")) 
```

```{r output_all}
readr::write_csv(dat_corr, "dat_all.csv")
readr::write_csv(dat_corr2, "dat_all_lag_sens_analysis.csv")
```



